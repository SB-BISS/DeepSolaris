{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Investigation of how the model performing best and being trained on images from NRW annotated by us\n",
    "### performs on the >30.000 images data set from California\n",
    "\n",
    "# It investigates \n",
    "#1)  how does the best model (xception model with pre-trained weights from imagenet and all layers set to trainable during the \n",
    "#    further training process on the NRW data set) perform on the California data set\n",
    "\n",
    "#2) how it performs on the california and NRW data set if it is further trained on the Cali data set for 5 epochs\n",
    "\n",
    "#3) how the same model type (xception, pre-trained, all layers trainable) performs on the Cali and NRW dataset if it \n",
    "#   is not pre-trained on NRW data, but only on Cali data for 5 epochs\n",
    "\n",
    "#4) doing the same with the NRW data training for 48 epochs first and then evaluating on NRW and Cali data\n",
    "\n",
    "#5) then retraining this data set for 5 epochs on the Cali data set and evaluating again on NRW and Cali data\n",
    "\n",
    "#6) then checking if it is an exception occuring only for the Xception network or if any of the other models pre-trained on \n",
    "#   the NRW data set is performing better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setting the different directories \n",
    "\n",
    "# on the server (linux):\n",
    "# where to find the images:\n",
    "#home_dir = '/home/rick/Documents/HannahZ'\n",
    "# folder where to save code and so on\n",
    "#code_dir = home_dir + '/Code'\n",
    "# where to save the final models\n",
    "#model_dir = code_dir + '/Final_models'\n",
    "# where to save the logs for visualization in TensorBoard\n",
    "#log_dir = code_dir + '/logs'\n",
    "# where to save the weights\n",
    "#new_weight_dir = code_dir + '/new_weights'\n",
    "\n",
    "# # on my computer (windows):\n",
    "# # where to find the images:\n",
    "home_dir = '\\\\Users\\\\ThinkPad User\\\\Google Drive\\\\DeepSolaris'\n",
    "# # folder where to save code and so on\n",
    "code_dir = '\\\\Users\\\\ThinkPad User\\\\Google Drive\\\\Master_thesis_H_Z_DL&NN\\\\Results'\n",
    "# # where to save the final models\n",
    "model_dir = 'E:\\\\FinalModels\\\\'\n",
    "# # where to save the logs for visualization in TensorBoard\n",
    "log_dir = code_dir + '\\\\logs'\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir(home_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t31776\n",
      "- Test-set:\t\t7946\n"
     ]
    }
   ],
   "source": [
    "### Loading the images from California (over 30.000 just for training)\n",
    "\n",
    "os.chdir(home_dir)\n",
    "train_images = np.load('train_images_Bradbury.npy')\n",
    "# valid_images = np.load('validation_images_AcMüDüHo.npy')\n",
    "test_images = np.load('test_images_Bradbury.npy')\n",
    "train_labels = np.load('train_labels_Bradbury.npy')\n",
    "# valid_labels = np.load('validation_labels_AcMüDüHo.npy')\n",
    "test_labels = np.load('test_labels_Bradbury.npy')\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(train_labels)))\n",
    "# print(\"- Validation-set:\\t{}\".format(len(valid_labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t3357\n",
      "- Validation-set:\t374\n",
      "- Test-set:\t\t934\n"
     ]
    }
   ],
   "source": [
    "### Loading the images from NRW I used for my thesis\n",
    "\n",
    "os.chdir(home_dir)\n",
    "Atrain_images = np.load('training_images_AcMüDüHo.npy')\n",
    "Avalid_images = np.load('validation_images_AcMüDüHo.npy')\n",
    "Atest_images = np.load('test_images_AcMüDüHo.npy')\n",
    "Atrain_labels = np.load('training_labels_AcMüDüHo.npy')\n",
    "Avalid_labels = np.load('validation_labels_AcMüDüHo.npy')\n",
    "Atest_labels = np.load('test_labels_AcMüDüHo.npy')\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(Atrain_labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(Avalid_labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(Atest_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t1848\n",
      "- Test-set:\t\t464\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_dir)\n",
    "Htrain_images = np.load('train_images_CBS.npy')\n",
    "Htest_images = np.load('test_images_CBS.npy')\n",
    "Htrain_labels = np.load('train_labels_CBS.npy')\n",
    "Htest_labels = np.load('test_labels_CBS.npy')\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(Htrain_labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(Htest_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# for i in range(3):\n",
    "#     print('Cali')\n",
    "#     ex = train_images[i]\n",
    "#     #plt.imshow(ex)\n",
    "#     #plt.show()\n",
    "#     ex = cv2.resize(ex, (300, 300))\n",
    "#     cv2.imshow('example', ex)\n",
    "#     cv2.waitKey(1200)\n",
    "#     cv2.destroyAllWindows()  \n",
    "#     print('NRW')\n",
    "#     #plt.imshow(Atrain_images[i])\n",
    "#     #plt.show()\n",
    "#     ex2 = cv2.resize(Atrain_images[i], (300, 300))\n",
    "#     cv2.imshow('NRW', ex2)\n",
    "#     cv2.waitKey(2400)\n",
    "#     cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Loading the relevant packages\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "from random import randrange\n",
    "from random import seed\n",
    "from random import sample\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Helper metrics functions\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall   \n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "def fmeasure(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n",
    "\n",
    "no_of_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DenseNet121_bs-128_triangular_sz-157_blr-1e-06_mlr-0.0002_e-48_imagenet_141_2-e30',\n",
       " 'DenseNet121_bs-64_triangular_sz-315_blr-1e-05_mlr-0.0009_e-48_imagenet_Frozen_3-e04',\n",
       " 'DenseNet121_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0003_e-96_imagenet_All_2-e08',\n",
       " 'IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0001_e-48_imagenet_595_3-e29',\n",
       " 'IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0003_e-96_imagenet_All_3-e63',\n",
       " 'IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0005_e-48_imagenet_Frozen_4-e16',\n",
       " 'IncV3_bs-64_triangular2_sz-315_blr-1e-05_mlr-0.0002_e-96_imagenet_All_0-e04',\n",
       " 'IncV3_bs-64_triangular2_sz-315_blr-1e-06_mlr-0.0001_e-96_imagenet_Frozen_4-e08',\n",
       " 'IncV3_bs-64_triangular2_sz-420_blr-1e-06_mlr-0.0002_e-96_imagenet_229__ensemble__',\n",
       " 'Xception_bs-128_triangular_sz-157_blr-1e-06_mlr-0.0002_e-48_imagenet_Frozen_3-e42',\n",
       " 'Xception_bs-128_triangular_sz-157_blr-1e-06_mlr-0.0004_e-96_imagenet_All_1-e73',\n",
       " 'Xception_bs-64_triangular_sz-315_blr-5e-05_mlr-0.0006_e-48_imagenet_86_3-e19']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Loading the model which performed best on the NRW test set, from all the models build before\n",
    "\n",
    "bestModelName = 'Xception_bs-128_triangular_sz-157_blr-1e-06_mlr-0.0004_e-96_imagenet_All_1-e73'\n",
    "from keras.models import load_model\n",
    "os.chdir(model_dir)\n",
    "boModel = load_model(bestModelName, \n",
    "                     custom_objects={'precision': precision, 'recall': recall, \n",
    "                                                            'fbeta_score': fbeta_score, 'fmeasure': fmeasure})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Evaluating the best-of-model on the data set of Heerlen\n",
    "print('    Heerlen      ')\n",
    "print('train_metrics') \n",
    "HtrainingRes = boModel.evaluate(Htrain_images, Htrain_labels)\n",
    "for i, j in zip(metrics,HtrainingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('test_metrics') \n",
    "HtestingRes = boModel.evaluate(Htest_images, Htest_labels)\n",
    "for i, j in zip(metrics,HtestingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       California           \n",
      "train_metrics\n",
      "31776/31776 [==============================] - 44s 1ms/step\n",
      "loss         :\t1.4672\n",
      "acc          :\t0.7287\n",
      "precision    :\t0.7200\n",
      "recall       :\t0.7496\n",
      "fmeasure     :\t0.7287\n",
      "\n",
      "test_metrics\n",
      "7946/7946 [==============================] - 11s 1ms/step\n",
      "loss         :\t1.5187\n",
      "acc          :\t0.7230\n",
      "precision    :\t0.7120\n",
      "recall       :\t0.7501\n",
      "fmeasure     :\t0.7249\n"
     ]
    }
   ],
   "source": [
    "### Evaluating the best-of-model on the Californian data set from BradBury\n",
    "\n",
    "print('       California           ')\n",
    "print('train_metrics') \n",
    "trainingRes = boModel.evaluate(train_images, train_labels)\n",
    "metrics = boModel.metrics_names\n",
    "for i, j in zip(metrics,trainingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('')\n",
    "print('test_metrics') \n",
    "testingRes = boModel.evaluate(test_images, test_labels)\n",
    "for i, j in zip(metrics,testingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "\n",
    "# -> worse than guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       NRW           \n",
      "train_metrics\n",
      "3357/3357 [==============================] - 5s 1ms/step\n",
      "loss         :\t1.2569\n",
      "acc          :\t0.8108\n",
      "precision    :\t0.7796\n",
      "recall       :\t0.8650\n",
      "fmeasure     :\t0.8155\n",
      "test_metrics\n",
      "934/934 [==============================] - 1s 1ms/step\n",
      "loss         :\t1.2356\n",
      "acc          :\t0.8201\n",
      "precision    :\t0.7776\n",
      "recall       :\t0.9085\n",
      "fmeasure     :\t0.8345\n"
     ]
    }
   ],
   "source": [
    "### Evaluating it on the data is was already trained and tested on just to check if the loadig worked\n",
    "\n",
    "print('       NRW           ')\n",
    "print('train_metrics') \n",
    "AtrainingRes = boModel.evaluate(Atrain_images, Atrain_labels)\n",
    "metrics = boModel.metrics_names\n",
    "for i, j in zip(metrics,AtrainingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('test_metrics') \n",
    "AtestingRes = boModel.evaluate(Atest_images, Atest_labels)\n",
    "for i, j in zip(metrics,AtestingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "\n",
    "# -> it worked as the model performs as good as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31776/31776 [==============================] - 26s 831us/step - loss: 0.4566 - acc: 0.8313 - precision: 0.8343 - recall: 0.8295 - fmeasure: 0.8262\n",
      "Epoch 2/5\n",
      "31776/31776 [==============================] - 25s 786us/step - loss: 0.3098 - acc: 0.8754 - precision: 0.8575 - recall: 0.9028 - fmeasure: 0.87814s - loss: 0.3098 - acc: 0.8757 - pre\n",
      "Epoch 3/5\n",
      "31776/31776 [==============================] - 25s 776us/step - loss: 0.2871 - acc: 0.8841 - precision: 0.8658 - recall: 0.9110 - fmeasure: 0.8867\n",
      "Epoch 4/5\n",
      "31776/31776 [==============================] - 25s 783us/step - loss: 0.2700 - acc: 0.8902 - precision: 0.8710 - recall: 0.9180 - fmeasure: 0.89269s - loss: 0.2735 - acc: 0.8866 - preci - ETA: 4s - loss: 0.2710 - acc: 0.8881 - precisi\n",
      "Epoch 5/5\n",
      "31776/31776 [==============================] - 25s 788us/step - loss: 0.2577 - acc: 0.8956 - precision: 0.8782 - recall: 0.9205 - fmeasure: 0.8977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f32bc75aa50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Retraining the best-of-model on the data from the Bradbury data set with the same hyperparameters for 5 epochs\n",
    "\n",
    "os.chdir(code_dir)\n",
    "from CyclicLR import CyclicLR\n",
    "clr = CyclicLR(base_lr = 0.000001, max_lr=0.0004,\n",
    "                        step_size= 157, mode = 'triangular')\n",
    "boModel.fit(x = train_images, y = train_labels, epochs = 5, callbacks= [clr], batch_size = 128, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for California:\n",
      "train_metrics\n",
      "31776/31776 [==============================] - 44s 1ms/step\n",
      "loss         :\t1.2182\n",
      "acc          :\t0.7281\n",
      "precision    :\t0.6485\n",
      "recall       :\t0.9975\n",
      "fmeasure     :\t0.7820\n",
      "\n",
      "test_metrics\n",
      "7946/7946 [==============================] - 11s 1ms/step\n",
      "loss         :\t1.2788\n",
      "acc          :\t0.7240\n",
      "precision    :\t0.6457\n",
      "recall       :\t0.9957\n",
      "fmeasure     :\t0.7794\n",
      "\n",
      "for NRW:\n",
      "train_metrics\n",
      "3357/3357 [==============================] - 5s 1ms/step\n",
      "loss         :\t2.0641\n",
      "acc          :\t0.6571\n",
      "precision    :\t0.5929\n",
      "recall       :\t0.9883\n",
      "fmeasure     :\t0.7373\n",
      "\n",
      "test_metrics\n",
      "934/934 [==============================] - 1s 1ms/step\n",
      "loss         :\t2.2196\n",
      "acc          :\t0.6488\n",
      "precision    :\t0.5928\n",
      "recall       :\t0.9872\n",
      "fmeasure     :\t0.7384\n"
     ]
    }
   ],
   "source": [
    "### checking the results of the retraining\n",
    "\n",
    "print('for California:')\n",
    "print('train_metrics') \n",
    "trainingRes = boModel.evaluate(train_images, train_labels)\n",
    "for i, j in zip(metrics,trainingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('')\n",
    "print('test_metrics') \n",
    "testingRes = boModel.evaluate(test_images, test_labels)\n",
    "for i, j in zip(metrics,testingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('')\n",
    "\n",
    "print('for NRW:')\n",
    "print('train_metrics') \n",
    "AtrainingRes = boModel.evaluate(Atrain_images, Atrain_labels)\n",
    "for i, j in zip(metrics,AtrainingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('')\n",
    "print('test_metrics') \n",
    "AtestingRes = boModel.evaluate(Atest_images, Atest_labels)\n",
    "for i, j in zip(metrics,AtestingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### chosing the model that performed best (Xception using transfer learning and having all layers trainable), and training it\n",
    "### directly on the Bradbury data sets without using the pre-trained weigths learned from the NRW data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose training specifications (None or 'imagenet')\n",
    "weights = 'imagenet'\n",
    "from keras.applications import xception\n",
    "\n",
    "# importing the currently used model\n",
    "os.chdir(code_dir)\n",
    "### create the base pre-trained model\n",
    "# usually takes around 30 seconds\n",
    "Model_base = xception.Xception(weights = weights, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras import Model\n",
    "\n",
    "def compileModel():\n",
    "    global Final_model\n",
    "    x = Model_base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    preds = Dense(1, activation='sigmoid')(x)\n",
    "    Final_model = Model(inputs=Model_base.input, outputs=preds)\n",
    "    for layer in Model_base.layers:   # only train the new layers first\n",
    "        layer.trainable = True\n",
    "    Final_model.compile(optimizer='rmsprop', loss='binary_crossentropy', \n",
    "                            metrics=['accuracy', precision, recall, fmeasure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xception_bs-128_triangular_sz-157_blr-1e-06_mlr-0.0004_e-96_imagenet_All_1-e73\n"
     ]
    }
   ],
   "source": [
    "print(bestModelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet\n",
      "All\n"
     ]
    }
   ],
   "source": [
    "###################### first training stage ###################################\n",
    "weights = 'imagenet'\n",
    "trainable_layers = 'All'\n",
    "batch_size = 128\n",
    "step_size = 157\n",
    "base_lr = 0.000006\n",
    "max_lr = 0.00001\n",
    "epochs = 96\n",
    "mode = 'triangular'\n",
    "def train_Model(verbose =1, times = 2, epochs = epochs, base_lr = base_lr, max_lr= max_lr, mode = mode, \n",
    "                stepsize = step_size, batch_size = batch_size, use_tensorboard = False, \n",
    "                train_images = train_images, train_labels = train_labels):\n",
    "    start_time = time()   \n",
    "    global h\n",
    "    global no_of_epochs\n",
    "    global name\n",
    "    date = str(datetime.now().date())\n",
    "    # logdir in linux:\n",
    "    logdir = (log_dir + '/' + date + '_' + str(batch_size) + '_' + str(mode) + '_si-' + str(stepsize) + '_base-' \n",
    "              + str(base_lr) + '_max-' + str(max_lr) + '_' + str(times))\n",
    "    name = ('batch size: ' + str(batch_size) + ', mode: ' + str(mode) + ', stepsize: ' \n",
    "            + str(stepsize) + ', base-lr: ' + str(base_lr) + ', max-lr ' + str(max_lr) + ', *' + str(times))\n",
    "    print(' - Model specifics:\\t{}'.format(name))\n",
    "    clr = CyclicLR(base_lr = base_lr, max_lr=max_lr,\n",
    "                        step_size= stepsize, mode = mode)\n",
    "    tbCallBack = TensorBoard(log_dir=logdir, histogram_freq=0, \n",
    "                         write_graph=False, write_images=False)\n",
    "    if (use_tensorboard == True):\n",
    "        Final_model.fit(x = train_images, y = train_labels, epochs = epochs, callbacks= [tbCallBack, clr], \n",
    "                            batch_size = batch_size, \n",
    "                            verbose = verbose)\n",
    "    else:\n",
    "        Final_model.fit(x = train_images, y = train_labels, epochs = epochs, callbacks= [clr], \n",
    "                            batch_size = batch_size, \n",
    "                            verbose = verbose)\n",
    "    no_of_epochs = no_of_epochs + epochs\n",
    "    h = []\n",
    "    h = clr.history\n",
    "    end_time = time()\n",
    "    time_dif = end_time - start_time\n",
    "    print('Time usage: ' + str(timedelta(seconds=int(round(time_dif)))) + ' minutes')\n",
    "print(weights)\n",
    "print(trainable_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Training only for 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Model specifics:\tbatch size: 128, mode: triangular, stepsize: 157, base-lr: 6e-06, max-lr 1e-05, *1\n",
      "Epoch 1/5\n",
      "31776/31776 [==============================] - 103s 3ms/step - loss: 0.5327 - acc: 0.7909 - precision: 0.7171 - recall: 0.9857 - fmeasure: 0.8268\n",
      "Epoch 2/5\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.4089 - acc: 0.9160 - precision: 0.8748 - recall: 0.9730 - fmeasure: 0.9202\n",
      "Epoch 3/5\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.2190 - acc: 0.9450 - precision: 0.9310 - recall: 0.9618 - fmeasure: 0.9453\n",
      "Epoch 4/5\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.1098 - acc: 0.9588 - precision: 0.9538 - recall: 0.9649 - fmeasure: 0.9586\n",
      "Epoch 5/5\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0762 - acc: 0.9698 - precision: 0.9682 - recall: 0.9716 - fmeasure: 0.9695\n",
      "Time usage: 0:08:16 minutes\n"
     ]
    }
   ],
   "source": [
    "Final_model = []\n",
    "compileModel()\n",
    "train_Model(verbose =1, times = 1, epochs = 5, base_lr = base_lr, max_lr= max_lr, mode = mode, \n",
    "                stepsize = step_size, batch_size = batch_size, use_tensorboard = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# already achieve an accuracy of >90% even on the test set\n",
    "# this makes very little sense to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for California:\n",
      "train_metrics\n",
      "31776/31776 [==============================] - 45s 1ms/step\n",
      "loss         :\t1.2182\n",
      "acc          :\t0.7281\n",
      "precision    :\t0.6485\n",
      "recall       :\t0.9975\n",
      "fmeasure     :\t0.7820\n",
      "\n",
      "test_metrics\n",
      "7946/7946 [==============================] - 11s 1ms/step\n",
      "loss         :\t1.2788\n",
      "acc          :\t0.7240\n",
      "precision    :\t0.6457\n",
      "recall       :\t0.9957\n",
      "fmeasure     :\t0.7794\n",
      "\n",
      "for NRW:\n",
      "train_metrics\n",
      "3357/3357 [==============================] - 5s 1ms/step\n",
      "loss         :\t2.0641\n",
      "acc          :\t0.6571\n",
      "precision    :\t0.5929\n",
      "recall       :\t0.9883\n",
      "fmeasure     :\t0.7373\n",
      "\n",
      "test_metrics\n",
      "934/934 [==============================] - 1s 1ms/step\n",
      "loss         :\t2.2196\n",
      "acc          :\t0.6488\n",
      "precision    :\t0.5928\n",
      "recall       :\t0.9872\n",
      "fmeasure     :\t0.7384\n"
     ]
    }
   ],
   "source": [
    "### checking the results for California \n",
    "print('for California:')\n",
    "print('train_metrics') \n",
    "trainingRes = boModel.evaluate(train_images, train_labels)\n",
    "for i, j in zip(metrics,trainingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('')\n",
    "print('test_metrics') \n",
    "testingRes = boModel.evaluate(test_images, test_labels)\n",
    "for i, j in zip(metrics,testingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('')\n",
    "\n",
    "#... and NRW: \n",
    "print('for NRW:')\n",
    "print('train_metrics') \n",
    "AtrainingRes = boModel.evaluate(Atrain_images, Atrain_labels)\n",
    "for i, j in zip(metrics,AtrainingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('')\n",
    "print('test_metrics') \n",
    "AtestingRes = boModel.evaluate(Atest_images, Atest_labels)\n",
    "for i, j in zip(metrics,AtestingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Model specifics:\tbatch size: 128, mode: triangular, stepsize: 157, base-lr: 6e-06, max-lr 1e-05, *1\n",
      "Epoch 1/5\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0542 - acc: 0.9808 - precision: 0.9815 - recall: 0.9801 - fmeasure: 0.9805\n",
      "Epoch 2/5\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0353 - acc: 0.9882 - precision: 0.9899 - recall: 0.9866 - fmeasure: 0.9881\n",
      "Epoch 3/5\n",
      "31776/31776 [==============================] - 96s 3ms/step - loss: 0.0226 - acc: 0.9927 - precision: 0.9943 - recall: 0.9910 - fmeasure: 0.9926\n",
      "Epoch 4/5\n",
      "31776/31776 [==============================] - 96s 3ms/step - loss: 0.0155 - acc: 0.9955 - precision: 0.9971 - recall: 0.9940 - fmeasure: 0.9955\n",
      "Epoch 5/5\n",
      "31776/31776 [==============================] - 96s 3ms/step - loss: 0.0102 - acc: 0.9971 - precision: 0.9982 - recall: 0.9960 - fmeasure: 0.9971\n",
      "Time usage: 0:07:57 minutes\n"
     ]
    }
   ],
   "source": [
    "# train for 5 more epochs\n",
    "train_Model(verbose =1, times = 1, epochs = 5, base_lr = base_lr, max_lr= max_lr, mode = mode, \n",
    "                stepsize = step_size, batch_size = batch_size, use_tensorboard = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for California:\n",
      "train_metrics\n",
      "31776/31776 [==============================] - 45s 1ms/step\n",
      "loss         :\t1.2182\n",
      "acc          :\t0.7281\n",
      "precision    :\t0.6485\n",
      "recall       :\t0.9975\n",
      "fmeasure     :\t0.7820\n",
      "\n",
      "test_metrics\n",
      "7946/7946 [==============================] - 11s 1ms/step\n",
      "loss         :\t1.2788\n",
      "acc          :\t0.7240\n",
      "precision    :\t0.6457\n",
      "recall       :\t0.9957\n",
      "fmeasure     :\t0.7794\n",
      "\n",
      "for NRW:\n",
      "train_metrics\n",
      "3357/3357 [==============================] - 5s 1ms/step\n",
      "loss         :\t2.0641\n",
      "acc          :\t0.6571\n",
      "precision    :\t0.5929\n",
      "recall       :\t0.9883\n",
      "fmeasure     :\t0.7373\n",
      "\n",
      "test_metrics\n",
      "934/934 [==============================] - 1s 1ms/step\n",
      "loss         :\t2.2196\n",
      "acc          :\t0.6488\n",
      "precision    :\t0.5928\n",
      "recall       :\t0.9872\n",
      "fmeasure     :\t0.7384\n",
      "    Heerlen      \n",
      "train_metrics\n",
      "1848/1848 [==============================] - 3s 2ms/step\n",
      "loss         :\t3.4379\n",
      "acc          :\t0.5038\n",
      "precision    :\t0.5000\n",
      "recall       :\t0.5016\n",
      "fmeasure     :\t0.5007\n",
      "test_metrics\n",
      "464/464 [==============================] - 1s 2ms/step\n",
      "loss         :\t3.7953\n",
      "acc          :\t0.5065\n",
      "precision    :\t0.5006\n",
      "recall       :\t0.5517\n",
      "fmeasure     :\t0.5111\n"
     ]
    }
   ],
   "source": [
    "### checking the results for California \n",
    "print('for California:')\n",
    "print('train_metrics') \n",
    "trainingRes = boModel.evaluate(train_images, train_labels)\n",
    "for i, j in zip(metrics,trainingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('')\n",
    "print('test_metrics') \n",
    "testingRes = boModel.evaluate(test_images, test_labels)\n",
    "for i, j in zip(metrics,testingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('')\n",
    "\n",
    "#... and NRW: \n",
    "print('for NRW:')\n",
    "print('train_metrics') \n",
    "AtrainingRes = boModel.evaluate(Atrain_images, Atrain_labels)\n",
    "for i, j in zip(metrics,AtrainingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('')\n",
    "print('test_metrics') \n",
    "AtestingRes = boModel.evaluate(Atest_images, Atest_labels)\n",
    "for i, j in zip(metrics,AtestingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "    \n",
    "# ...and Heerlen\n",
    "print('    Heerlen      ')\n",
    "print('train_metrics') \n",
    "HtrainingRes = boModel.evaluate(Htrain_images, Htrain_labels)\n",
    "for i, j in zip(metrics,HtrainingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))\n",
    "print('test_metrics') \n",
    "HtestingRes = boModel.evaluate(Htest_images, Htest_labels)\n",
    "for i, j in zip(metrics,HtestingRes):\n",
    "    print('{:12} :\\t{:.4f}'.format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### to exclude that something went wrong with loading the model, the xception network is loaded as it is, then trained for 48 \n",
    "### epochs on the NRW data set and then trained again for 5 epochs on the Bradbury data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final_model = []\n",
    "compileModel()\n",
    "train_Model(verbose =1, times = 1, epochs = 5, base_lr = base_lr, max_lr= max_lr, mode = mode, \n",
    "                stepsize = step_size, batch_size = batch_size, use_tensorboard = False,\n",
    "           train_images = Atrain_images, train_labels = Atrain_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('    NRW      ')\n",
    "print('train_metrics') \n",
    "trainingAcc = Final_model.evaluate(Atrain_images, Atrain_labels)[1]\n",
    "print(trainingAcc)\n",
    "print('test_metrics') \n",
    "testingAcc = Final_model.evaluate(Atest_images, Atest_labels)[1]\n",
    "print(testingAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0071 - acc: 0.9983 - precision: 0.9988 - recall: 0.9980 - fmeasure: 0.9984\n",
      "Epoch 2/5\n",
      "31776/31776 [==============================] - 96s 3ms/step - loss: 0.0054 - acc: 0.9984 - precision: 0.9987 - recall: 0.9981 - fmeasure: 0.9984\n",
      "Epoch 3/5\n",
      "31776/31776 [==============================] - 96s 3ms/step - loss: 0.0048 - acc: 0.9990 - precision: 0.9992 - recall: 0.9989 - fmeasure: 0.9990\n",
      "Epoch 4/5\n",
      "31776/31776 [==============================] - 96s 3ms/step - loss: 0.0107 - acc: 0.9980 - precision: 0.9982 - recall: 0.9976 - fmeasure: 0.9979\n",
      "Epoch 5/5\n",
      "31776/31776 [==============================] - 96s 3ms/step - loss: 0.0055 - acc: 0.9985 - precision: 0.9986 - recall: 0.9983 - fmeasure: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f769b679510>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_model.fit(x = train_images, y = train_labels, epochs = 48, callbacks= [clr], \n",
    "                            batch_size = batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_metrics\n",
      "31776/31776 [==============================] - 45s 1ms/step\n",
      "[0.0019756040841845935, 0.9994335347432024, 0.99977174656388745, 0.99902841649867014, 0.99937881563845476]\n",
      "test_metrics\n",
      "7946/7946 [==============================] - 11s 1ms/step\n",
      "[0.16572030939293919, 0.97596274855273091, 0.98318925445157213, 0.96792361780104696, 0.97460047772030911]\n"
     ]
    }
   ],
   "source": [
    "### checking the results for California \n",
    "print('train_metrics') \n",
    "trainingAcc = Final_model.evaluate(train_images, train_labels)[1]\n",
    "print(trainingAcc)\n",
    "print('test_metrics') \n",
    "testingAcc = Final_model.evaluate(test_images, test_labels)[1]\n",
    "print(testingAcc)\n",
    "\n",
    "#... and NRW: \n",
    "print('    NRW      ')\n",
    "print('train_metrics') \n",
    "trainingAcc = Final_model.evaluate(Atrain_images, Atrain_labels)[1]\n",
    "print(trainingAcc)\n",
    "print('test_metrics') \n",
    "testingAcc = Final_model.evaluate(Atest_images, Atest_labels)[1]\n",
    "print(testingAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### then retraining it on the Cali-data-set for 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Model specifics:\tbatch size: 128, mode: triangular, stepsize: 157, base-lr: 6e-06, max-lr 0.0004, *1\n",
      "Epoch 1/96\n",
      "31776/31776 [==============================] - 103s 3ms/step - loss: 0.2106 - acc: 0.9262 - precision: 0.9106 - recall: 0.9575 - fmeasure: 0.9305\n",
      "Epoch 2/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0481 - acc: 0.9826 - precision: 0.9815 - recall: 0.9837 - fmeasure: 0.9824\n",
      "Epoch 3/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0246 - acc: 0.9920 - precision: 0.9915 - recall: 0.9926 - fmeasure: 0.9920\n",
      "Epoch 4/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0182 - acc: 0.9949 - precision: 0.9955 - recall: 0.9944 - fmeasure: 0.9949\n",
      "Epoch 5/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0159 - acc: 0.9957 - precision: 0.9953 - recall: 0.9961 - fmeasure: 0.9957\n",
      "Epoch 6/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0100 - acc: 0.9975 - precision: 0.9971 - recall: 0.9978 - fmeasure: 0.9974\n",
      "Epoch 7/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0086 - acc: 0.9981 - precision: 0.9982 - recall: 0.9981 - fmeasure: 0.9981\n",
      "Epoch 8/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0090 - acc: 0.9982 - precision: 0.9985 - recall: 0.9980 - fmeasure: 0.9982\n",
      "Epoch 9/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0117 - acc: 0.9969 - precision: 0.9971 - recall: 0.9968 - fmeasure: 0.9969\n",
      "Epoch 10/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0129 - acc: 0.9974 - precision: 0.9972 - recall: 0.9977 - fmeasure: 0.9974\n",
      "Epoch 11/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0085 - acc: 0.9980 - precision: 0.9976 - recall: 0.9983 - fmeasure: 0.9979\n",
      "Epoch 12/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0051 - acc: 0.9987 - precision: 0.9990 - recall: 0.9985 - fmeasure: 0.9987\n",
      "Epoch 13/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0099 - acc: 0.9983 - precision: 0.9982 - recall: 0.9984 - fmeasure: 0.9983\n",
      "Epoch 14/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0059 - acc: 0.9985 - precision: 0.9980 - recall: 0.9989 - fmeasure: 0.9984\n",
      "Epoch 15/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0069 - acc: 0.9983 - precision: 0.9976 - recall: 0.9988 - fmeasure: 0.9982\n",
      "Epoch 16/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0046 - acc: 0.9986 - precision: 0.9984 - recall: 0.9989 - fmeasure: 0.9986\n",
      "Epoch 17/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0080 - acc: 0.9987 - precision: 0.9988 - recall: 0.9987 - fmeasure: 0.9987\n",
      "Epoch 18/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0036 - acc: 0.9989 - precision: 0.9990 - recall: 0.9989 - fmeasure: 0.9989\n",
      "Epoch 19/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0044 - acc: 0.9990 - precision: 0.9993 - recall: 0.9988 - fmeasure: 0.9990\n",
      "Epoch 20/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0041 - acc: 0.9986 - precision: 0.9985 - recall: 0.9988 - fmeasure: 0.9987\n",
      "Epoch 21/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0057 - acc: 0.9989 - precision: 0.9990 - recall: 0.9988 - fmeasure: 0.9989\n",
      "Epoch 22/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0039 - acc: 0.9991 - precision: 0.9989 - recall: 0.9992 - fmeasure: 0.9991\n",
      "Epoch 23/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0067 - acc: 0.9990 - precision: 0.9991 - recall: 0.9988 - fmeasure: 0.9989\n",
      "Epoch 24/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0064 - acc: 0.9989 - precision: 0.9990 - recall: 0.9988 - fmeasure: 0.9989\n",
      "Epoch 25/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0062 - acc: 0.9985 - precision: 0.9987 - recall: 0.9984 - fmeasure: 0.9985\n",
      "Epoch 26/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0045 - acc: 0.9992 - precision: 0.9989 - recall: 0.9995 - fmeasure: 0.9992\n",
      "Epoch 27/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0029 - acc: 0.9993 - precision: 0.9992 - recall: 0.9995 - fmeasure: 0.9993\n",
      "Epoch 28/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0022 - acc: 0.9995 - precision: 0.9994 - recall: 0.9996 - fmeasure: 0.9995\n",
      "Epoch 29/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0026 - acc: 0.9995 - precision: 0.9994 - recall: 0.9995 - fmeasure: 0.9995\n",
      "Epoch 30/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0026 - acc: 0.9995 - precision: 0.9995 - recall: 0.9995 - fmeasure: 0.9995\n",
      "Epoch 31/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0054 - acc: 0.9993 - precision: 0.9990 - recall: 0.9996 - fmeasure: 0.9993\n",
      "Epoch 32/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0021 - acc: 0.9993 - precision: 0.9994 - recall: 0.9992 - fmeasure: 0.9993\n",
      "Epoch 33/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0044 - acc: 0.9994 - precision: 0.9996 - recall: 0.9993 - fmeasure: 0.9994\n",
      "Epoch 34/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0029 - acc: 0.9993 - precision: 0.9991 - recall: 0.9994 - fmeasure: 0.9993\n",
      "Epoch 35/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0100 - acc: 0.9988 - precision: 0.9986 - recall: 0.9989 - fmeasure: 0.9987\n",
      "Epoch 36/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0139 - acc: 0.9988 - precision: 0.9993 - recall: 0.9984 - fmeasure: 0.9988\n",
      "Epoch 37/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0017 - acc: 0.9997 - precision: 0.9998 - recall: 0.9996 - fmeasure: 0.9997\n",
      "Epoch 38/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0026 - acc: 0.9993 - precision: 0.9994 - recall: 0.9993 - fmeasure: 0.9993\n",
      "Epoch 39/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0026 - acc: 0.9997 - precision: 0.9997 - recall: 0.9995 - fmeasure: 0.9996\n",
      "Epoch 40/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0017 - acc: 0.9994 - precision: 0.9993 - recall: 0.9994 - fmeasure: 0.9994\n",
      "Epoch 41/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0032 - acc: 0.9995 - precision: 0.9994 - recall: 0.9996 - fmeasure: 0.9995\n",
      "Epoch 42/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0025 - acc: 0.9994 - precision: 0.9993 - recall: 0.9995 - fmeasure: 0.9994\n",
      "Epoch 43/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0043 - acc: 0.9994 - precision: 0.9993 - recall: 0.9995 - fmeasure: 0.9994\n",
      "Epoch 44/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0015 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998 - fmeasure: 0.9998\n",
      "Epoch 45/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0031 - acc: 0.9993 - precision: 0.9993 - recall: 0.9994 - fmeasure: 0.9993\n",
      "Epoch 46/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0011 - acc: 0.9999 - precision: 0.9999 - recall: 0.9998 - fmeasure: 0.9999\n",
      "Epoch 47/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0022 - acc: 0.9995 - precision: 0.9995 - recall: 0.9995 - fmeasure: 0.9995\n",
      "Epoch 48/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0024 - acc: 0.9995 - precision: 0.9994 - recall: 0.9995 - fmeasure: 0.9994\n",
      "Epoch 49/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0025 - acc: 0.9992 - precision: 0.9991 - recall: 0.9994 - fmeasure: 0.9993\n",
      "Epoch 50/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0044 - acc: 0.9995 - precision: 0.9995 - recall: 0.9995 - fmeasure: 0.9995\n",
      "Epoch 51/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 7.8995e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9997 - fmeasure: 0.9998\n",
      "Epoch 52/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0030 - acc: 0.9997 - precision: 0.9994 - recall: 0.9998 - fmeasure: 0.9996\n",
      "Epoch 53/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0040 - acc: 0.9994 - precision: 0.9994 - recall: 0.9995 - fmeasure: 0.9994\n",
      "Epoch 54/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0026 - acc: 0.9995 - precision: 0.9995 - recall: 0.9995 - fmeasure: 0.9995\n",
      "Epoch 55/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0010 - acc: 0.9997 - precision: 0.9997 - recall: 0.9997 - fmeasure: 0.9997\n",
      "Epoch 56/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0019 - acc: 0.9997 - precision: 0.9997 - recall: 0.9997 - fmeasure: 0.9997\n",
      "Epoch 57/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0016 - acc: 0.9995 - precision: 0.9994 - recall: 0.9997 - fmeasure: 0.9995\n",
      "Epoch 58/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0020 - acc: 0.9993 - precision: 0.9992 - recall: 0.9992 - fmeasure: 0.9992\n",
      "Epoch 59/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0010 - acc: 0.9997 - precision: 0.9996 - recall: 0.9998 - fmeasure: 0.9997\n",
      "Epoch 60/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0026 - acc: 0.9997 - precision: 0.9998 - recall: 0.9997 - fmeasure: 0.9997\n",
      "Epoch 61/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0024 - acc: 0.9994 - precision: 0.9996 - recall: 0.9993 - fmeasure: 0.9994\n",
      "Epoch 62/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0022 - acc: 0.9996 - precision: 0.9998 - recall: 0.9995 - fmeasure: 0.9996\n",
      "Epoch 63/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0013 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998 - fmeasure: 0.9998\n",
      "Epoch 64/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0016 - acc: 0.9997 - precision: 0.9998 - recall: 0.9997 - fmeasure: 0.9997\n",
      "Epoch 65/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0017 - acc: 0.9997 - precision: 0.9996 - recall: 0.9997 - fmeasure: 0.9997\n",
      "Epoch 66/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0024 - acc: 0.9997 - precision: 0.9995 - recall: 0.9998 - fmeasure: 0.9996\n",
      "Epoch 67/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 9.4892e-04 - acc: 0.9997 - precision: 0.9996 - recall: 0.9998 - fmeasure: 0.9997\n",
      "Epoch 68/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 6.9969e-04 - acc: 0.9998 - precision: 0.9996 - recall: 0.9999 - fmeasure: 0.9998\n",
      "Epoch 69/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0021 - acc: 0.9997 - precision: 0.9996 - recall: 0.9997 - fmeasure: 0.9997\n",
      "Epoch 70/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0018 - acc: 0.9997 - precision: 0.9996 - recall: 0.9998 - fmeasure: 0.9997\n",
      "Epoch 71/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 6.4451e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9999 - fmeasure: 0.9998\n",
      "Epoch 72/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0024 - acc: 0.9997 - precision: 0.9996 - recall: 0.9998 - fmeasure: 0.9997\n",
      "Epoch 73/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0016 - acc: 0.9998 - precision: 0.9999 - recall: 0.9998 - fmeasure: 0.9998\n",
      "Epoch 74/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0018 - acc: 0.9996 - precision: 0.9996 - recall: 0.9995 - fmeasure: 0.9995\n",
      "Epoch 75/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0012 - acc: 0.9998 - precision: 0.9999 - recall: 0.9997 - fmeasure: 0.9998\n",
      "Epoch 76/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0018 - acc: 0.9996 - precision: 0.9996 - recall: 0.9995 - fmeasure: 0.9996\n",
      "Epoch 77/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0043 - acc: 0.9994 - precision: 0.9992 - recall: 0.9996 - fmeasure: 0.9994\n",
      "Epoch 78/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0019 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998 - fmeasure: 0.9998\n",
      "Epoch 79/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0026 - acc: 0.9995 - precision: 0.9995 - recall: 0.9994 - fmeasure: 0.9995\n",
      "Epoch 80/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0012 - acc: 0.9997 - precision: 0.9995 - recall: 0.9997 - fmeasure: 0.9996\n",
      "Epoch 81/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0019 - acc: 0.9996 - precision: 0.9995 - recall: 0.9996 - fmeasure: 0.9996\n",
      "Epoch 82/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0012 - acc: 0.9997 - precision: 0.9997 - recall: 0.9998 - fmeasure: 0.9997\n",
      "Epoch 83/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0013 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998 - fmeasure: 0.9998\n",
      "Epoch 84/96\n",
      "31776/31776 [==============================] - 96s 3ms/step - loss: 8.6940e-04 - acc: 0.9998 - precision: 0.9999 - recall: 0.9998 - fmeasure: 0.9999\n",
      "Epoch 85/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0014 - acc: 0.9998 - precision: 0.9996 - recall: 0.9999 - fmeasure: 0.9998\n",
      "Epoch 86/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0015 - acc: 0.9996 - precision: 0.9997 - recall: 0.9995 - fmeasure: 0.9996\n",
      "Epoch 87/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 9.3065e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998 - fmeasure: 0.9998\n",
      "Epoch 88/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0014 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998 - fmeasure: 0.9998\n",
      "Epoch 89/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0045 - acc: 0.9997 - precision: 0.9994 - recall: 0.9999 - fmeasure: 0.9996\n",
      "Epoch 90/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 6.2688e-04 - acc: 0.9998 - precision: 0.9999 - recall: 0.9997 - fmeasure: 0.9998\n",
      "Epoch 91/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0010 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998 - fmeasure: 0.9999\n",
      "Epoch 92/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0014 - acc: 0.9997 - precision: 0.9996 - recall: 0.9997 - fmeasure: 0.9997\n",
      "Epoch 93/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 0.0028 - acc: 0.9995 - precision: 0.9992 - recall: 0.9998 - fmeasure: 0.9995\n",
      "Epoch 94/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0021 - acc: 0.9997 - precision: 0.9997 - recall: 0.9998 - fmeasure: 0.9997\n",
      "Epoch 95/96\n",
      "31776/31776 [==============================] - 95s 3ms/step - loss: 9.9298e-04 - acc: 0.9998 - precision: 0.9999 - recall: 0.9998 - fmeasure: 0.9998\n",
      "Epoch 96/96\n",
      "31776/31776 [==============================] - 94s 3ms/step - loss: 0.0010 - acc: 0.9998 - precision: 0.9997 - recall: 0.9999 - fmeasure: 0.9998\n",
      "Time usage: 2:31:53 minutes\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "compileModel()\n",
    "train_Model(verbose =1, times = 1, epochs = 5, base_lr = base_lr, max_lr= max_lr, mode = mode, \n",
    "                stepsize = step_size, batch_size = batch_size, use_tensorboard = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_metrics\n",
      "31776/31776 [==============================] - 42s 1ms/step\n",
      "0.6074\n",
      "test_metrics\n",
      "7946/7946 [==============================] - 11s 1ms/step\n",
      "0.6063\n"
     ]
    }
   ],
   "source": [
    "### checking the results for California \n",
    "print('train_metrics') \n",
    "trainingAcc = Final_model.evaluate(train_images, train_labels)[1]\n",
    "print(trainingAcc)\n",
    "print('test_metrics') \n",
    "testingAcc = Final_model.evaluate(test_images, test_labels)[1]\n",
    "print(testingAcc)\n",
    "\n",
    "#... and NRW: \n",
    "print('    NRW      ')\n",
    "print('train_metrics') \n",
    "trainingAcc = Final_model.evaluate(Atrain_images, Atrain_labels)[1]\n",
    "print(trainingAcc)\n",
    "print('test_metrics') \n",
    "testingAcc = Final_model.evaluate(Atest_images, Atest_labels)[1]\n",
    "print(testingAcc)\n",
    "\n",
    "# ...and Heerlen\n",
    "print('    Heerlen      ')\n",
    "print('train_metrics') \n",
    "trainingAcc = boModel.evaluate(Htrain_images, Htrain_labels)[1]\n",
    "print(trainingAcc)\n",
    "print('test_metrics') \n",
    "testingAcc = boModel.evaluate(Htest_images, Htest_labels)[1]\n",
    "print(testingAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### checking if it is an exception occuring only for the Xception network or if any of the other models pre-trained on the\n",
    "### NRW data set is performing better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IncV3_bs-64_triangular2_sz-420_blr-1e-06_mlr-0.0002_e-96_imagenet_229__ensemble__\n",
      "31776/31776 [==============================] - 39s 1ms/step\n",
      "7946/7946 [==============================] - 8s 1ms/step\n",
      "IncV3_bs-64_triangular2_sz-315_blr-1e-06_mlr-0.0001_e-96_imagenet_Frozen_4-e08\n",
      "31776/31776 [==============================] - 42s 1ms/step\n",
      "7946/7946 [==============================] - 8s 1ms/step\n",
      "IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0005_e-48_imagenet_Frozen_4-e16\n",
      "31776/31776 [==============================] - 84s 3ms/step\n",
      "7946/7946 [==============================] - 17s 2ms/step\n",
      "Xception_bs-128_triangular_sz-157_blr-1e-06_mlr-0.0002_e-48_imagenet_Frozen_3-e42\n",
      "31776/31776 [==============================] - 67s 2ms/step\n",
      "7946/7946 [==============================] - 13s 2ms/step\n",
      "IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0003_e-96_imagenet_All_3-e63\n",
      "31776/31776 [==============================] - 95s 3ms/step\n",
      "7946/7946 [==============================] - 18s 2ms/step\n",
      "Xception_bs-128_triangular_sz-157_blr-1e-06_mlr-0.0004_e-96_imagenet_All_1-e73\n",
      "31776/31776 [==============================] - 79s 2ms/step\n",
      "7946/7946 [==============================] - 15s 2ms/step\n",
      "DenseNet121_bs-128_triangular_sz-157_blr-1e-06_mlr-0.0002_e-48_imagenet_141_2-e30\n",
      "31776/31776 [==============================] - 80s 3ms/step\n",
      "7946/7946 [==============================] - 14s 2ms/step\n",
      "DenseNet121_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0003_e-96_imagenet_All_2-e08\n",
      "31776/31776 [==============================] - 86s 3ms/step\n",
      "7946/7946 [==============================] - 14s 2ms/step\n",
      "IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0001_e-48_imagenet_595_3-e29\n",
      "31776/31776 [==============================] - 113s 4ms/step\n",
      "7946/7946 [==============================] - 19s 2ms/step\n",
      "DenseNet121_bs-64_triangular_sz-315_blr-1e-05_mlr-0.0009_e-48_imagenet_Frozen_3-e04\n",
      "31776/31776 [==============================] - 97s 3ms/step\n",
      "7946/7946 [==============================] - 15s 2ms/step\n",
      "Xception_bs-64_triangular_sz-315_blr-5e-05_mlr-0.0006_e-48_imagenet_86_3-e19\n",
      "31776/31776 [==============================] - 107s 3ms/step\n",
      "7946/7946 [==============================] - 17s 2ms/step\n",
      "IncV3_bs-64_triangular2_sz-315_blr-1e-05_mlr-0.0002_e-96_imagenet_All_0-e04\n",
      "31776/31776 [==============================] - 101s 3ms/step\n",
      "7946/7946 [==============================] - 13s 2ms/step\n",
      "Time usage: 0:39:45 minutes\n"
     ]
    }
   ],
   "source": [
    "os.chdir(model_dir)\n",
    "nameList = os.listdir(model_dir)\n",
    "def evalModels():\n",
    "    start_time = time()\n",
    "    global test_acc_list; global train_acc_list; global test_loss_list\n",
    "    global train_loss_list; global test_prec_list\n",
    "    global train_prec_list; global test_rec_list; global train_rec_list\n",
    "    global model_details\n",
    "    model_details = []; test_acc_list = []; train_acc_list = []; test_loss_list = []\n",
    "    train_loss_list = []; test_prec_list = []\n",
    "    train_prec_list = []; test_rec_list = []; train_rec_list = []\n",
    "    for name in nameList:\n",
    "        print(name)\n",
    "        Final_model = load_model(name, custom_objects={'precision': precision, 'recall': recall, \n",
    "                                 'fbeta_score': fbeta_score, 'fmeasure': fmeasure})\n",
    "        train_metrics = Final_model.evaluate(train_images, train_labels)\n",
    "        test_metrics = Final_model.evaluate(test_images, test_labels)\n",
    "        train_acc = train_metrics[1]; test_acc = test_metrics[1]\n",
    "        train_loss = train_metrics[0]; test_loss = test_metrics[0]\n",
    "        train_prec = train_metrics[2];  test_prec = test_metrics[2]\n",
    "        train_rec = train_metrics[3]; test_rec = test_metrics[3]         \n",
    "        test_acc_list.append(test_acc); train_acc_list.append(train_acc)\n",
    "        test_loss_list.append(test_loss); train_loss_list.append(train_loss)\n",
    "        test_prec_list.append(test_prec); train_prec_list.append(train_prec)\n",
    "        test_rec_list.append(test_rec); train_rec_list.append(train_rec)\n",
    "        model_details.append(name)\n",
    "    end_time = time()\n",
    "    time_dif = end_time - start_time\n",
    "    print('Time usage: ' + str(timedelta(seconds=int(round(time_dif)))) + ' minutes')\n",
    "evalModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test acc</th>\n",
       "      <th>test loss</th>\n",
       "      <th>test prec</th>\n",
       "      <th>test rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DenseNet121_bs-64_triangular_sz-315_blr-1e-05_mlr-0.0009_e-48_imagenet_Frozen_3-e04</th>\n",
       "      <td>0.639819</td>\n",
       "      <td>3.216919</td>\n",
       "      <td>0.614226</td>\n",
       "      <td>0.747921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DenseNet121_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0003_e-96_imagenet_All_2-e08</th>\n",
       "      <td>0.621319</td>\n",
       "      <td>4.400646</td>\n",
       "      <td>0.570508</td>\n",
       "      <td>0.980548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DenseNet121_bs-128_triangular_sz-157_blr-1e-06_mlr-0.0002_e-48_imagenet_141_2-e30</th>\n",
       "      <td>0.607350</td>\n",
       "      <td>4.450650</td>\n",
       "      <td>0.562837</td>\n",
       "      <td>0.964576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncV3_bs-64_triangular2_sz-315_blr-1e-06_mlr-0.0001_e-96_imagenet_Frozen_4-e08</th>\n",
       "      <td>0.602316</td>\n",
       "      <td>5.770830</td>\n",
       "      <td>0.589164</td>\n",
       "      <td>0.682436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncV3_bs-64_triangular2_sz-315_blr-1e-05_mlr-0.0002_e-96_imagenet_All_0-e04</th>\n",
       "      <td>0.500126</td>\n",
       "      <td>7.968705</td>\n",
       "      <td>0.500081</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0005_e-48_imagenet_Frozen_4-e16</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.059048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0003_e-96_imagenet_All_3-e63</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.059048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_mlr-0.0001_e-48_imagenet_595_3-e29</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.059048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncV3_bs-64_triangular2_sz-420_blr-1e-06_mlr-0.0002_e-96_imagenet_229__ensemble__</th>\n",
       "      <td>0.497861</td>\n",
       "      <td>4.983025</td>\n",
       "      <td>0.498976</td>\n",
       "      <td>0.988217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xception_bs-128_triangular_sz-157_blr-1e-06_mlr-0.0002_e-48_imagenet_Frozen_3-e42</th>\n",
       "      <td>0.495344</td>\n",
       "      <td>7.825194</td>\n",
       "      <td>0.498004</td>\n",
       "      <td>0.979937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xception_bs-128_triangular_sz-157_blr-1e-06_mlr-0.0004_e-96_imagenet_All_1-e73</th>\n",
       "      <td>0.360307</td>\n",
       "      <td>9.597677</td>\n",
       "      <td>0.382656</td>\n",
       "      <td>0.449676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xception_bs-64_triangular_sz-315_blr-5e-05_mlr-0.0006_e-48_imagenet_86_3-e19</th>\n",
       "      <td>0.355776</td>\n",
       "      <td>8.900431</td>\n",
       "      <td>0.371805</td>\n",
       "      <td>0.418504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    test acc  test loss  \\\n",
       "DenseNet121_bs-64_triangular_sz-315_blr-1e-05_m...  0.639819   3.216919   \n",
       "DenseNet121_bs-64_triangular_sz-315_blr-1e-06_m...  0.621319   4.400646   \n",
       "DenseNet121_bs-128_triangular_sz-157_blr-1e-06_...  0.607350   4.450650   \n",
       "IncV3_bs-64_triangular2_sz-315_blr-1e-06_mlr-0....  0.602316   5.770830   \n",
       "IncV3_bs-64_triangular2_sz-315_blr-1e-05_mlr-0....  0.500126   7.968705   \n",
       "IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_m...  0.500000   8.059048   \n",
       "IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_m...  0.500000   8.059048   \n",
       "IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_m...  0.500000   8.059048   \n",
       "IncV3_bs-64_triangular2_sz-420_blr-1e-06_mlr-0....  0.497861   4.983025   \n",
       "Xception_bs-128_triangular_sz-157_blr-1e-06_mlr...  0.495344   7.825194   \n",
       "Xception_bs-128_triangular_sz-157_blr-1e-06_mlr...  0.360307   9.597677   \n",
       "Xception_bs-64_triangular_sz-315_blr-5e-05_mlr-...  0.355776   8.900431   \n",
       "\n",
       "                                                    test prec  test rec  \n",
       "DenseNet121_bs-64_triangular_sz-315_blr-1e-05_m...   0.614226  0.747921  \n",
       "DenseNet121_bs-64_triangular_sz-315_blr-1e-06_m...   0.570508  0.980548  \n",
       "DenseNet121_bs-128_triangular_sz-157_blr-1e-06_...   0.562837  0.964576  \n",
       "IncV3_bs-64_triangular2_sz-315_blr-1e-06_mlr-0....   0.589164  0.682436  \n",
       "IncV3_bs-64_triangular2_sz-315_blr-1e-05_mlr-0....   0.500081  1.000000  \n",
       "IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_m...   0.000000  0.000000  \n",
       "IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_m...   0.000000  0.000000  \n",
       "IncResNetV2_bs-64_triangular_sz-315_blr-1e-06_m...   0.000000  0.000000  \n",
       "IncV3_bs-64_triangular2_sz-420_blr-1e-06_mlr-0....   0.498976  0.988217  \n",
       "Xception_bs-128_triangular_sz-157_blr-1e-06_mlr...   0.498004  0.979937  \n",
       "Xception_bs-128_triangular_sz-157_blr-1e-06_mlr...   0.382656  0.449676  \n",
       "Xception_bs-64_triangular_sz-315_blr-5e-05_mlr-...   0.371805  0.418504  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData = np.array((test_acc_list, test_loss_list, test_prec_list, test_rec_list, train_acc_list))\n",
    "testColumns = ['test acc', 'test loss', 'test prec', 'test rec', 'train acc']\n",
    "shortRes = pd.DataFrame(data = testData, columns = model_details, index = testColumns)\n",
    "ShortAllModelOvw = pd.DataFrame(data = shortRes.transpose(), columns = testColumns, index = model_details)\n",
    "ShortAllModelOvw.sort_values(by=['test acc'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation with bootstrapping\n",
    "seed(1)\n",
    "ratio = 0.1    # proportion of data that is used for subsample\n",
    "\n",
    "def subsample(dataset, labels = test_labels, ratio= ratio):\n",
    "    pred_sample = list()\n",
    "    label_sample = list()\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    index = sample(range(len(dataset)), n_sample)\n",
    "    pred_sample = dataset[index]\n",
    "    label_sample = labels[index]           \n",
    "    return pred_sample, label_sample\n",
    "\n",
    "def bootstrap(dataset, iterations = 20, ratio = ratio, labels = test_labels):    \n",
    "    for i in range (iterations):\n",
    "        b_pred, b_labels = subsample(dataset, labels, ratio)\n",
    "        lo = cross_entropy(b_pred, b_labels)\n",
    "        b_pred_rounded = b_pred.round()\n",
    "        acc = accuracy_score(b_labels, b_pred_rounded)\n",
    "        pre = precision_score(b_labels, b_pred_rounded)\n",
    "        rec = recall_score(b_labels, b_pred_rounded)\n",
    "        loss.append(lo)\n",
    "        accuracy.append(acc)\n",
    "        precisions.append(pre)\n",
    "        recalls.append(rec)\n",
    "        if (i%1000 == 0): \n",
    "            print('Iteration_' + str(i))\n",
    "            \n",
    "def cross_entropy(predictions, targets, epsilon=1e-12):\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(np.sum(targets*np.log(predictions+1e-9)))/N\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boPreds = boModel.predict(test_images, batch_size = 64).squeeze(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration_0\n",
      "Iteration_1000\n",
      "Iteration_2000\n",
      "Iteration_3000\n",
      "Iteration_4000\n",
      "Iteration_5000\n",
      "Iteration_6000\n",
      "Iteration_7000\n",
      "Iteration_8000\n",
      "Iteration_9000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x425239b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f_measures = []\n",
    "\n",
    "### for the best of Model\n",
    "%matplotlib inline\n",
    "bootstrap(iterations = 10000, dataset = boPreds)\n",
    "plt.hist(accuracy, bins = 700, range = [0,1])\n",
    "plt.show\n",
    "acc_boModel = accuracy\n",
    "loss_boModel = loss\n",
    "pre_boModel = precisions\n",
    "rec_boModel = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(precisions, bins = 100, range = [0,1], color = 'forestgreen')\n",
    "#plt.hist(recalls, bins = 100, range = [0,1], color = 'indianred')\n",
    "#plt.hist(loss, bins = 100, color = 'skyblue')\n",
    "#plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading the best model from the mixed training\n",
    "ModelName = 'FINAL'\n",
    "os.chdir(model_dir)\n",
    "mixedModel = load_model(ModelName, \n",
    "                     custom_objects={'precision': precision, 'recall': recall, \n",
    "                                                            'fbeta_score': fbeta_score, 'fmeasure': fmeasure})\n",
    "mixedPreds = mixedModel.predict(test_images, batch_size = 64).squeeze(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration_0\n",
      "Iteration_1000\n",
      "Iteration_2000\n",
      "Iteration_3000\n",
      "Iteration_4000\n",
      "Iteration_5000\n",
      "Iteration_6000\n",
      "Iteration_7000\n",
      "Iteration_8000\n",
      "Iteration_9000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4ae25c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### for the mixed Model\n",
    "loss = []\n",
    "accuracy = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "bootstrap(iterations = 10000, dataset = mixedPreds)\n",
    "plt.hist(accuracy, bins = 700, range = [0,1])\n",
    "#plt.hist(precisions, bins = 100, range = [0,1])\n",
    "#plt.hist(recalls, bins = 100, range = [0,1])\n",
    "#plt.hist(loss, bins = 100)\n",
    "\n",
    "acc_mixedModel = accuracy\n",
    "loss_mixedModel = loss\n",
    "pre_mixedModel = precisions\n",
    "rec_mixedModel = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7e3ed710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(acc_boModel, bins = 800, range = [0,1], color = 'darkorchid', alpha = 0.6)\n",
    "plt.hist(acc_mixedModel, bins = 800, range = [0,1], color = 'royalblue', alpha = 0.6)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0224\n",
      "0.0171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0141"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-Hypothesis:  both accuracies are the same\n",
    "# Alternative-H: both accuracies are different\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "N = 10000\n",
    "a = np.array(acc_mixedModel)\n",
    "b = np.array(acc_boModel)\n",
    "\n",
    "#For unbiased max likelihood estimate we have to divide the var by N-1, and therefore the parameter ddof = 1\n",
    "var_a = a.var(ddof=1)\n",
    "var_b = b.var(ddof=1)\n",
    "print(round(var_a, 6)*100)\n",
    "print(round(var_b, 6)*100)\n",
    "#std deviation\n",
    "s = np.sqrt((var_a + var_b)/2)\n",
    "round(s, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = -441.372222632\n",
      "p = nan\n"
     ]
    }
   ],
   "source": [
    "## Calculate the t-statistics\n",
    "t = (a.mean() - b.mean())/(s*np.sqrt(2/N))\n",
    "## Compare with the critical t-value\n",
    "#Degrees of freedom\n",
    "df = 2*N - 2\n",
    "\n",
    "#p-value after comparison with the t \n",
    "p = 1 - stats.t.cdf(t,df=df)\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(2*p))\n",
    "#Note that we multiply the p value by 2 because its a twp tail t-test\n",
    "### You can see that after comparing the t statistic with the critical t value (computed internally) we get a good p value \n",
    "# of 0.0005 and thus we reject the null hypothesis and thus it proves that the mean of the two distributions are different \n",
    "# and statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = -441.372222632\n",
      "p = 0.0\n"
     ]
    }
   ],
   "source": [
    "## Cross Checking with the internal scipy function\n",
    "t2, p2 = stats.ttest_ind(acc_mixedModel ,acc_boModel)\n",
    "print(\"t = \" + str(t2))\n",
    "print(\"p = \" + str(2*p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration_0\n",
      "Iteration_1000\n",
      "Iteration_2000\n",
      "Iteration_3000\n",
      "Iteration_4000\n",
      "Iteration_5000\n",
      "Iteration_6000\n",
      "Iteration_7000\n",
      "Iteration_8000\n",
      "Iteration_9000\n"
     ]
    }
   ],
   "source": [
    "### Now for the NRW data\n",
    "\n",
    "### for the best of Model\n",
    "boPreds = boModel.predict(Atest_images, batch_size = 64).squeeze(axis = 1)\n",
    "loss = []; accuracy = []; precisions = []; recalls = []; f_measures = []\n",
    "\n",
    "bootstrap(iterations = 10000, dataset = boPreds, labels = Atest_labels)\n",
    "NRW_acc_boModel = accuracy\n",
    "NRW_loss_boModel = loss\n",
    "NRW_pre_boModel = precisions\n",
    "NRW_rec_boModel = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.87096774193548387,\n",
       " 0.79569892473118276,\n",
       " 0.81720430107526887,\n",
       " 0.76344086021505375,\n",
       " 0.79569892473118276,\n",
       " 0.83870967741935487,\n",
       " 0.90322580645161288,\n",
       " 0.84946236559139787,\n",
       " 0.76344086021505375,\n",
       " 0.82795698924731187]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NRW_acc_boModel[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NRW_acc_mixedModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration_0\n",
      "Iteration_1000\n",
      "Iteration_2000\n",
      "Iteration_3000\n",
      "Iteration_4000\n",
      "Iteration_5000\n",
      "Iteration_6000\n",
      "Iteration_7000\n",
      "Iteration_8000\n",
      "Iteration_9000\n"
     ]
    }
   ],
   "source": [
    "### for the mixed Model\n",
    "mixedPreds = mixedModel.predict(Atest_images, batch_size = 64).squeeze(axis = 1)\n",
    "loss = []; accuracy = []; precisions = []; recalls = []; f_measures = []\n",
    "\n",
    "bootstrap(iterations = 10000, dataset = mixedPreds, labels = Atest_labels)\n",
    "NRW_acc_mixedModel = accuracy\n",
    "NRW_loss_mixedModel = loss\n",
    "NRW_pre_mixedModel = precisions\n",
    "NRW_rec_mixedModel = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD9CAYAAAC1DKAUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131cd1518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(NRW_acc_boModel, bins = 90, range = [0,1], color = 'b', alpha =0.5)\n",
    "plt.hist(NRW_acc_mixedModel, bins = 90, range = [0,1], color = 'r', alpha =0.5)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance mixedModel: \t0.1652\n",
      "variance boModel: \t0.1407\n",
      "standard deviation: \t0.0141 \n"
     ]
    }
   ],
   "source": [
    "# 0-Hypothesis:  both accuracies are the same\n",
    "# Alternative-H: both accuracies are different\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "N = 10000\n",
    "NRW_a = np.array(NRW_acc_mixedModel)\n",
    "NRW_b = np.array(NRW_acc_boModel)\n",
    "\n",
    "#For unbiased max likelihood estimate we have to divide the var by N-1, and therefore the parameter ddof = 1\n",
    "var_aNRW = NRW_a.var(ddof=1)\n",
    "var_bNRW = NRW_b.var(ddof=1)\n",
    "print('variance mixedModel: \\t{}'.format(round(var_aNRW, 6)*100))\n",
    "print('variance boModel: \\t{}'.format(round(var_bNRW, 6)*100))\n",
    "#std deviation\n",
    "sNRW = np.sqrt((var_aNRW + var_bNRW)/2)\n",
    "print('standard deviation: \\t{} '.format(round(s, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 67.1007731575\n",
      "p = 0.0\n"
     ]
    }
   ],
   "source": [
    "## Calculate the t-statistics\n",
    "tNRW = (NRW_b.mean() - NRW_a.mean())/(sNRW*np.sqrt(2/N))\n",
    "## Compare with the critical t-value\n",
    "#Degrees of freedom\n",
    "df = 2*N - 2\n",
    "\n",
    "#p-value after comparison with the t \n",
    "pNRW = 1 - stats.t.cdf(tNRW,df=df)\n",
    "print(\"t = \" + str(tNRW))\n",
    "print(\"p = \" + str(2*pNRW))\n",
    "#Note that we multiply the p value by 2 because its a twp tail t-test\n",
    "### You can see that after comparing the t statistic with the critical t value (computed internally) we get a good p value \n",
    "# of 0.0005 and thus we reject the null hypothesis and thus it proves that the mean of the two distributions are different \n",
    "# and statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = -67.1007731575\n",
      "p = 0.0\n"
     ]
    }
   ],
   "source": [
    "## Cross Checking with the internal scipy function\n",
    "NRWt2, NRWp2 = stats.ttest_ind(NRW_acc_mixedModel ,NRW_acc_boModel)\n",
    "print(\"t = \" + str(NRWt2))\n",
    "print(\"p = \" + str(2*NRWp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# compare to second-best model                                                             #\n",
    "############################################################################################\n",
    "os.chdir(model_dir)\n",
    "sbModel = load_model('Xception_bs-64_triangular_sz-315_blr-5e-05_mlr-0.0006_e-48_imagenet_86_3-e19', \n",
    "                     custom_objects={'precision': precision, 'recall': recall, 'fbeta_score': fbeta_score, 'fmeasure': fmeasure})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration_0\n",
      "Iteration_1000\n",
      "Iteration_2000\n",
      "Iteration_3000\n",
      "Iteration_4000\n",
      "Iteration_5000\n",
      "Iteration_6000\n",
      "Iteration_7000\n",
      "Iteration_8000\n",
      "Iteration_9000\n"
     ]
    }
   ],
   "source": [
    "### for the best of Model\n",
    "sbPreds = sbModel.predict(Atest_images, batch_size = 64).squeeze(axis = 1)\n",
    "loss = []; accuracy = []; precisions = []; recalls = []; f_measures = []\n",
    "\n",
    "bootstrap(iterations = 10000, dataset = sbPreds, labels = Atest_labels)\n",
    "NRW_acc_sbModel = accuracy\n",
    "NRW_loss_sbModel = loss\n",
    "NRW_pre_sbModel = precisions\n",
    "NRW_rec_sbModel = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.80645161290322576,\n",
       " 0.76344086021505375,\n",
       " 0.83870967741935487,\n",
       " 0.86021505376344087,\n",
       " 0.76344086021505375,\n",
       " 0.75268817204301075,\n",
       " 0.86021505376344087,\n",
       " 0.84946236559139787,\n",
       " 0.91397849462365588,\n",
       " 0.88172043010752688]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NRW_acc_sbModel[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD9CAYAAAC1DKAUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVr9wBTU5DwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7cf420b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(NRW_acc_boModel, bins = 95, range = [0,1], color = 'b', alpha =0.5)\n",
    "plt.hist(NRW_acc_sbModel, bins = 95, range = [0,1], color = 'forestgreen', alpha =0.5)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance mixedModel: \t0.1508\n",
      "variance boModel: \t0.1407\n",
      "standard deviation: \t0.0382 \n"
     ]
    }
   ],
   "source": [
    "# 0-Hypothesis:  both accuracies are the same\n",
    "# Alternative-H: both accuracies are different\n",
    "\n",
    "N = 10000\n",
    "aSB = np.array(NRW_acc_sbModel)\n",
    "bSB = np.array(NRW_acc_boModel)\n",
    "\n",
    "#For unbiased max likelihood estimate we have to divide the var by N-1, and therefore the parameter ddof = 1\n",
    "var_aSB = aSB.var(ddof=1)\n",
    "var_bSB = bSB.var(ddof=1)\n",
    "print('variance mixedModel: \\t{}'.format(round(var_aSB, 6)*100))\n",
    "print('variance boModel: \\t{}'.format(round(var_bSB, 6)*100))\n",
    "#std deviation\n",
    "sSB = np.sqrt((var_aSB + var_bSB)/2)\n",
    "print('standard deviation: \\t{} '.format(round(sSB, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820524731183\n",
      "0.814407526882\n"
     ]
    }
   ],
   "source": [
    "print(bSB.mean())\n",
    "print(aSB.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 11.3291156128\n",
      "p = 0.0\n"
     ]
    }
   ],
   "source": [
    "## Calculate the t-statistics\n",
    "tSB = (bSB.mean() - aSB.mean())/(sSB*np.sqrt(2/N))\n",
    "## Compare with the critical t-value\n",
    "#Degrees of freedom\n",
    "df = 2*N - 2\n",
    "\n",
    "#p-value after comparison with the t \n",
    "pSB = 1 - stats.t.cdf(tSB,df=df)\n",
    "print(\"t = \" + str(tSB))\n",
    "print(\"p = \" + str(2*pSB))\n",
    "#Note that we multiply the p value by 2 because its a twp tail t-test\n",
    "### You can see that after comparing the t statistic with the critical t value (computed internally) we get a good p value \n",
    "# of 0.0005 and thus we reject the null hypothesis and thus it proves that the mean of the two distributions are different \n",
    "# and statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = -11.3291156128\n",
      "p = 2.31896449395e-29\n"
     ]
    }
   ],
   "source": [
    "## Cross Checking with the internal scipy function\n",
    "t2SB, p2SB = stats.ttest_ind(NRW_acc_sbModel ,NRW_acc_boModel)\n",
    "print(\"t = \" + str(t2SB))\n",
    "print(\"p = \" + str(2*p2SB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
